{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06cb672",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7c60974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c2bcc",
   "metadata": {},
   "source": [
    "### Color Channels, the RGB Colorspace\n",
    "\n",
    "We will see how to load an image, find colors within the image and detect the ball and goal-post\n",
    "\n",
    "First, we get an image, then separate the color channels and observe how it appears in each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "364a46d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('view.png')\n",
    "  \n",
    "# Displaying the image\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "blue = img[:, :, 0]\n",
    "green = img[:, :, 1]\n",
    "red = img[:, :, 2]\n",
    "\n",
    "cv2.imshow('Blue channel', blue)\n",
    "cv2.imshow('Green channel', green)\n",
    "cv2.imshow('Red channel', red)\n",
    "\n",
    "# cv2.imwrite('view_blue.png', blue)\n",
    "# cv2.imwrite('view_green.png', green)\n",
    "# cv2.imwrite('view_red.png', red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d6701",
   "metadata": {},
   "source": [
    "### Hue, Saturation, Value - HSV Color Space\n",
    "\n",
    "Since colors are not apparent in the RGB color space, we try the HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69d4bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "red_mask = cv2.inRange(hsv, np.array([0,10,10]), np.array([20,255,255]))\n",
    "\n",
    "# Bitwise-AND mask and original image\n",
    "red_parts = cv2.bitwise_and(img, img, mask= red_mask)\n",
    "\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.imshow('Red Hue Mask', red_mask)\n",
    "cv2.imshow('Masked Image', red_parts)\n",
    "\n",
    "# cv2.imwrite('hue_mask.png', red_mask)\n",
    "# cv2.imwrite('hue_red.png', red_parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb95eec",
   "metadata": {},
   "source": [
    "Finding the goal post, opponent and the ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76655708",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "\n",
    "red_mask = cv2.inRange(hsv, np.array([0,10,10]), np.array([5,255,255]))\n",
    "orange_mask = cv2.inRange(hsv, np.array([5,10,10]), np.array([20,255,255]))\n",
    "blue_mask = cv2.inRange(hsv, np.array([100,10,10]), np.array([160,255,255]))\n",
    "\n",
    "red_parts = cv2.bitwise_and(img, img, mask= red_mask)\n",
    "orange_parts = cv2.bitwise_and(img, img, mask= orange_mask)\n",
    "blue_parts = cv2.bitwise_and(img, img, mask= blue_mask)\n",
    "\n",
    "cv2.imshow('Goal Post', red_parts)\n",
    "cv2.imshow('Ball', orange_parts)\n",
    "cv2.imshow('Opponent', blue_parts)\n",
    "\n",
    "# cv2.imwrite('goal.png', red_parts)\n",
    "# cv2.imwrite('ball.png', orange_parts)\n",
    "# cv2.imwrite('opponent.png', blue_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68f599",
   "metadata": {},
   "source": [
    "### Image Masks, Denoising and Detecting Connected Regions\n",
    "\n",
    "For all practical purposes, finding the appropriate masks will suffice.\n",
    "\n",
    "We use the color masks to detect the ball, opponent and goalpost, find their relative position to our bot and take decisions accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eabdcb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_image = np.copy(img)\n",
    "\n",
    "# Red contour\n",
    "contours = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (255,0,255), 4)\n",
    "    \n",
    "# Blue contour\n",
    "contours = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (255,255,0), 4)\n",
    "    \n",
    "# Orange contour\n",
    "contours = cv2.findContours(orange_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (0,255,255), 4)\n",
    "\n",
    "    \n",
    "cv2.imshow('Bounding Box', overlay_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba077dd1",
   "metadata": {},
   "source": [
    "We first apply denoising (morphological opening) to remove the rogue pixels from the mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2dadca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "\n",
    "opening_red = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)\n",
    "opening_orange = cv2.morphologyEx(orange_mask, cv2.MORPH_OPEN, kernel)\n",
    "opening_blue = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "overlay_image = np.copy(img)\n",
    "\n",
    "# Red contour\n",
    "contours = cv2.findContours(opening_red, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (255,0,255), 4)\n",
    "    \n",
    "# Blue contour\n",
    "contours = cv2.findContours(opening_blue, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (255,255,0), 4)\n",
    "    \n",
    "# Orange contour\n",
    "contours = cv2.findContours(opening_orange, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "\n",
    "for i in contours:\n",
    "    x,y,w,h = cv2.boundingRect(i)\n",
    "    cv2.rectangle(overlay_image, (x, y), (x + w, y + h), (0,255,255), 4)\n",
    "\n",
    "    \n",
    "cv2.imshow('Bounding Box', overlay_image)\n",
    "\n",
    "# cv2.imwrite('detections.png', overlay_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
